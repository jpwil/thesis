% \begin{savequote}[8cm]
%     Quote goes here.
%     % For IPD meta-analysis situations, it can also be expensive, time consuming, and \textit{generally painstaking} to obtain and clean the raw data from multiple studies. --- Richard Riley et al.\cite{riley2016}
%     \qauthor{ --- Author}
% \end{savequote}

\chapter{\label{ch:4-isc-model-methodology}Model methodology}
\minitoc

\section{Introduction}

As outlined in Chapter~\ref{ch:2-background}, VL relapse is consequential not only for individual patients but also poses a threat to sustained elimination efforts. Accordingly, the development of a non-invasive tool to predict relapse \textemdash\ functioning as a `test--of--cure' following initial treatment \textemdash\ has been identified by the WHO as a research priority\cite{WHO2024_Leishmaniasis,WHO_2024_VL_easternAfrica,who_sea_elim}. A prognostic model represents a potential solution: by quantifying the relationship between patient characteristics and subsequent relapse events, relapse risk in future patients can be estimated and clinical decision-making informed. However, as demonstrated in Chapter~\ref{ch:3-sys-review}, no prognostic models for VL relapse have been published to date.

To address this evidence gap, four prognostic models are developed using IPD from the IDDO VL data platform: two for patients from the ISC and two for patients from East Africa. Within each region, one model includes parasite grade at initial cure assessment, and one model excludes parasite grade, reflecting differences in data availability and clinical practice. All models use routinely collected information available at the time of initial cure assessment to predict six-month relapse among VL patients without HIV co-infection.

The development and evaluation of clinical prediction models is supported by an extensive and growing methodological literature. Over the past decade, reporting guidelines for prediction model studies have been established\cite{collins2015, moons2015, debray2023, collins2024A}, alongside an increasing number of reviews and recommendations that define best practice\cite{efthimiou2024, collins2024B, riley2024A, riley2024B, vanSmeden2021}. In particular, the application of meta-analysis techniques to IPD from multiple studies presents exciting new opportunities for prediction model development and evaluation\cite{riley2021_book_ch17, debray2023}. Notable opportunities include increased sample sizes leading to greater statistical power, and the ability to explore heterogeneity in predictor effects and model performance across different settings. Additionally, IPD can be used to standardise inclusion criteria and outcome/predictor definitions across included studies. However, as we lay out in this chapter, the use of IPD in prediction model research also introduces challenges; specifically (i) the need for statistical models that account for clustering of participants within studies and (ii) the presence of missing data, which can be sporadically missing within studies, or entirely missing from one or more studies\cite{debray2023}.

The aim of this chapter is to describe and justify the methodology used for model development and evaluation \textemdash\ from data acquisition to final model presentation. Guidelines and methodological texts are cited accordingly, and checklists provided for current reporting guidelines on prediction model studies (TRIPOD-AI and TRIPOD-Cluster)\cite{collins2024A,debray2023}. Additional material is presented in Appendix \ref{app:methodology} and in the \href{https://github.com/jpwil/dphil}{Supplementary Material}.\footnote{Available at \url{https://github.com/jpwil/dphil}.} A protocol is available on the \href{https://osf.io/z4bdn}{Open Science Framework}.\footnote{Created Nov 8, 2024, available at \url{https://osf.io/z4bdn}.}

This chapter's structure closely mirrors the methodological workflow as outlined in Figure~\ref{fig:workflow}, with sections on data harmonisation, model development, and internal validation. In keeping with best practice, and similar to the approach adopted in Chapter \ref{ch:3-sys-review}, the research question is presented in Box \ref{box:picots} using the PICOTS (population, index model, comparator model, outcome, timing, and setting) framework\cite{riley2021_book_ch17, debray2017}. Further elaboration of the eligibility criteria, and standardised definitions of predictors and the outcome are considered in the following section.

All analyses were performed using R version 4.4.1\cite{r2025}, with R packages cited in the relevant sections below. R scripts used for model development and evaluation are provided in the \href{https://github.com/jpwil/dphil}{Supplementary Material}.

\begin{mybox}[label=box:picots]{Definition of the research question: a PICOTS approach}
    \begin{description}[nosep]
        \item[Population] HIV-negative patients that are prospectively recruited into a clinical trial with a diagnosis of visceral leishmaniasis, confirmed either serologically or parasitologically. No restrictions are placed on age, sex or treatment regimen.
        \item[Index models] For each setting, two prognostic models are developed; one including baseline parasite grade from a tissue aspirate, and one without. The models predict the \textit{future} occurrence of relapse, using patient information collected at treatment baseline. The intended time of model use is following a successful assessment of treatment response.
        \item[Comparator model] As established in Chapter \ref{ch:3-sys-review}, no published relapse models are available for comparison or updating.
        \item[Outcome] Relapse is defined as the recurrence of signs and symptoms of VL requiring rescue treatment, and following demonstration of an initial treatment response.
        \item[Timing] Relapse occurring within 6--months of test--of--cure (typically occurring at the time of treatment completion, or within 30 days of starting treatment).
        \item[Setting] Participants from either the Indian subcontinent or East Africa.
    \end{description}
\end{mybox}

\section{Data harmonisation}

Here, data harmonisation refers to the process of data acquisition, curation, and any subsequent data manipulation required to produce a single analysis dataset ready for model development.

In the interest of full disclosure, data acquisition was completed by IDDO colleagues prior to the commencement of this DPhil project. The first stage of data curation \textemdash\ conversion of the contributed datasets to the Clinical Data Interchange Standards Consortium (CDISC) Study Data Tabulation Model (SDTM) standard \textemdash\ was performed by the IDDO data engineering team with support from the IDDO science team (myself included). Subsequent methodological steps were led by myself.

\subsection{Data acquisition}

A systematic review of the scientific literature was first performed in 2016, with the aim of comprehensively cataloguing all existing VL clinical trials (PROSPERO: \href{https://www.crd.york.ac.uk/PROSPERO/view/CRD42021284622}{CRD42021284622})\cite{bush2017}. 145 trials were initially identified (1980--2016, n = 26,986 patients), with further trials added during periodic updates according to an open protocol\cite{Singh-Phulgenda2022_IDDO_VL_protocol}. Between 2018--2022, corresponding authors of the identified VL clinical trials were invited to share their IPD with the IDDO VL data platform, in line with the General Data Protection Regulation (GDPR)--compliant IDDO data sharing policy\cite{IDDO_DataGovernance, dahal2025}.

\subsection{Data curation}

Conversion of the contributed datasets to an analysis--ready dataset of all eligible IPD occurred in two key stages.

\subsubsection{Stage 1: CDISC SDTM curation}

To facilitate reusability and interoperability, contributed datasets were standardised to a common storage format: the CDISC--compliant SDTM standard\cite{cdisc2024}, adapted by IDDO for VL\cite{iddo2020}. During this process, contributed datasets underwent \textit{psuedonymisation},\footnote{\ `\dots processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information' \url{https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/data-sharing/anonymisation/pseudonymisation/} (accessed 15 Dec 2025).} prior to being available for data sharing requests. Briefly, SDTM format datasets comprise a number of standardised domains (tables) containing related information (e.g. patient demographics, laboratory results, treatment administration, clinical signs and symptoms). Each domain contains a set of standard variables (table columns, e.g. STUDYID, USUBJID, VISITDY) alongside VL--specific variables defined by IDDO (e.g. parasite grade, spleen size). Further details of the curation process are available in the \href{https://www.iddo.org/tools-and-resources/data-tools}{IDDO SDTM Implementation Guide}.\footnote{Available at \url{https://www.iddo.org/tools-and-resources/data-tools}, free registration required.}

\newgeometry{left=1cm, bottom=2.5cm, right=2cm, top=3cm}
\begin{landscape}
    \begin{figure}[tb]
        \centering
        \includegraphics[width=1.2\textwidth, trim={1.6cm 1cm 1.6cm 1.3cm}, clip]{figures/ch4/workflow.pdf}
        \caption{Schema of methodological workflow. \ding{192} Data harmonisation is performed for each contributed dataset including: initial curation (by the IDDO data engineering team) to the CDISC SDTM format, application of inclusion and exclusion criteria, and removal of outliers. Curated and cleaned datasets are converted into an analysis (wide) format and merged prior to \ding{193} model development. Multiple imputation is used to create (m = 30) imputed (complete) datasets. Variable selection, model fitting, and apparent performance evaluation is performed on all imputed datasets. Estimates are pooled using Rubin's rules. Bootstrapping is used to perform \ding{194} internal validation, allowing (i) review of model stability and (ii) optimism adjustment of performance measures and original model coefficients. All model development steps, including multiple imputation, are repeated for each of the (b = 500) bootstrap datasets. The resulting bootstrap models (b = 500) are evaluated both in the corresponding bootstrap (imputed) datasets and the original (imputed) datasets, and pooled using Rubin's rules. The mean of the differences of the pooled performance measures (in bootstrap vs. original dataset) are used to shrink the original model coefficients and apparent performance measures, resulting in the final optimism-adjusted model. AP: apparent performance; b: number of bootstraps; BP: bootstrap model performance; CDISC: Clinical Data Interchange Standards Consortium; IDDO: infectious diseases data observatory; m: number of imputations; n: number of contributed studies. SDTM: Study Data Tabulation Model.}
        \label{fig:workflow}
    \end{figure}
\end{landscape}
\restoregeometry

\subsubsection{Stage 2: Analysis--ready dataset curation}

Subsequently, SDTM format datasets were converted to a single analysis--ready dataset, primed for model development. This stage consisted of multiple steps, refined iteratively over several months and in close consultation with the IDDO data engineering team:

\begin{itemize}[noitemsep]
    \item Identification and removal of spurious data points (e.g. outliers, discussed below)
    \item Application of study and participant eligibility criteria (Section \ref{sec:eligibility})
    \item Creation of a standardised outcome variable according to a pre-defined definition (Section \ref{sec:methods-outcome})
    \item Conversion of the datasets from a long to wide format, consisting of one row per participant
    \item Merging of all datasets into a single analysis dataset
\end{itemize}

Data wrangling during the second curation stage was performed with the \texttt{tidyverse} suite of R packages\cite{wickham2019}. Identification and removal of spurious data points was performed through subgroup tabulations and visual inspection of histograms and scatter plots. Where two incongruous data points were identified, for example, incompatible height and weight values, a third variable, such as BMI or age, would be used to identify the spurious value. Data points considered to be outliers were converted to missing values. A complete record of all data cleaning steps, including outlier identification and removal, was maintained and documented in commented R scripts.

In Section \ref{sec:relapse} of Chapter \ref{ch:2-background}, relapse was defined broadly as `the reappearance of VL signs and symptoms following an initial treatment response', and `typically confirmed by direct visualisation of the parasite on a tissue aspirate smear'. Despite appearing a clear definition, on closer inspection it can be appreciated that even subtle variations in eligibility criteria, study design, and the definition of efficacy endpoints can, at times unexpectedly, impact the proportion of patients experiencing relapse as a study outcome.

\subsection{\label{sec:eligibility}Population at risk}

Clear specification of the population at risk is fundamental to understanding the model's real-world applicability\cite{riley2021_book_ch17, collins2024A}. Particular attention is given to the definition of initial cure, since (i) relapse can only occur following an initial treatment response, and (ii) heterogeneity in study-level cure definitions can be partially addressed through IPD--based standardisation.

Inclusion and exclusion criteria were applied at the study and participant levels and are presented in Box \ref{box:eligibility}. Criteria are chosen according to (i) the eligibility criteria applied in the original systematic review from which identified study authors were invited to contribute their IPD\cite{bush2017}, (ii) the range of studies available in the IDDO VL data platform, and (iii) the resulting impact and applicability of models developed.

\begin{mybox}[floatplacement=tb, label=box:eligibility]{Eligibility criteria}
    \begin{itemize}[nosep]
        \item \textbf{Study--level \underline{inclusion} criteria}
              \begin{itemize}
                  \item Studies conducted in either the ISC (India, Nepal, Bangladesh) or East Africa (Ethiopia, Sudan, South Sudan, Kenya, Uganda)
                  \item Prospective design, defined as participants having provided informed consent
                  \item Participants recruited with a diagnosis of VL as defined by a combination of clinical symptoms and either parasitological or serological confirmation
                  \item Studies that report, as a minimum, the treatment regimen including at least the drug name(s), dose and duration
                  \item Recruited a minimum of 6 patients
                  \item Included a minimum of 6 months of prospective follow-up from treatment initiation
                  \item Reported VL relapse events during the 6-month follow-up period
              \end{itemize}
        \item \textbf{Participant--level \underline{exclusion} criteria}
              \begin{itemize}
                  \item Participants with HIV co-infection or from a setting with high HIV co-infection prevalence and without a negative HIV test
                  \item Participants who were confirmed pregnant at the time of treatment initiation
                  \item Participants with symptomatic treatment failure requiring rescue treatment, identified either before or at initial cure assessment
              \end{itemize}
    \end{itemize}
\end{mybox}

\subsubsection{Study--level criteria}

Study-level inclusion criteria were applied to ensure that contributing datasets were sufficiently comparable in terms of epidemiological context, study design, and outcome ascertainment to permit meaningful harmonisation and pooled analysis.

Studies were limited to those conducted in East Africa and the ISC, reflecting both the public health relevance of relapse prediction in regions with ongoing VL elimination programmes, and the availability of IPD within the IDDO VL data platform. On review of the IDDO inventory \cite{iddo2025vlinventory}, only two studies were conducted outside these regions \textemdash\ one in Greece conducted in the 1990s \cite{syriopoulou2003}, and one in Brazil in the 2010s \cite{romero2017}. These were excluded to preserve geographical and epidemiological coherence.

Only prospectively conducted studies were included. Prospective designs allow for systematic and active follow-up, predefined outcome definitions, and contemporaneous outcome recording, all of which are important for the reliable identification of initial cure and subsequent relapse. However, reliance on IPD derived from clinical trials limits the direct applicability of the resulting model to real-world patients \textemdash\ those who are managed outside trial settings, and may not meet the often--stringent eligibility criteria. These limitations are discussed further in Chapter~\ref{ch:7-discussion}.

A minimum study size was imposed to exclude very small cohorts with unstable relapse estimates. Finally, studies were required to report relapse events during follow-up, either explicitly or in a form that allowed relapse to be inferred from the available IPD.

\subsubsection{Participant--level criteria}

With respect to clinical presentation, treatment response, and outcomes, patients with VL/HIV co-infection constitute an important but distinct clinical population. Accordingly, patients with and without VL/HIV co-infection were \textit{not} combined within a single prediction model, given the substantial uncertainty in extrapolating relapse associations derived from HIV-negative patients to those with VL/HIV co-infection. Since the majority of contributing studies excluded patients with VL/HIV co-infection, insufficient IPD were available to develop a separate model for this group.

As with VL/HIV co-infection, very few contributing studies included pregnant participants, reflecting their systematic exclusion from VL trials and precluding the development of a separate prediction model.

\subsubsection{Initial cure}

Understanding study--specific definitions of initial cure is important, as all studies require the patient to demonstrate a treatment response, measured with a test--of--cure, in order to be at subsequent risk of relapse. Consequently, patients \textit{not} achieving initial cure \textemdash\ described as initial treatment failure \textemdash\ should be excluded. A direct consequence of excluding these patients is that model--derived risk estimates are only applicable to patients demonstrating initial cure.

Initial cure definitions based solely on clinical improvement, as is common in routine practice, are likely to classify some patients as cured despite persistently positive tissue aspirates, were these assessed. These patients form a subgroup at increased risk of relapse and would instead be classified as initial treatment failures under more stringent, parasitology-based test--of--cure criteria, thereby being excluded from subsequent follow-up. Consequently, all else being equal, studies applying stricter definitions of initial cure will observe a lower subsequent relapse risk.

Recently, Dahal and colleagues performed a systematic review of the design, conduct, analysis, and reporting of VL therapeutic efficacy studies, published between 2000--2021. Of the 89 studies identified, 71 (79.8\%) included parasitological assessment, with or without demonstration of clinical improvement, as part of the test--of--cure, while 13 (14.6\%) required clinical improvement only. The remaining studies did not provide a definition. Timing also varied considerably, with the 68 (76.4\%) of studies performing the test--of--cure between 15--30 days following treatment completion\cite{dahal2024}. Similar patterns are observed in the contributed studies, as reported in the \href{https://github.com/jpwil/dphil}{Supplemental Material}, and discussed further in subsequent results chapters. Importantly, criteria for `clinical improvement' are often not specified. Further complicating interpretation, many studies describe a subgroup of `slow responders', who remain in the study despite a positive tissue aspirate in the test--of--cure. These patients may undergo repeat assessment at subsequent time points (e.g. 2--4 weeks later), with or without treatment extension, and may or may not ultimately be classified as having achieved initial cure.

Such variation in the initial cure definition can challenge standardisation efforts, leading to differences in observed relapse rates  stemming from differences in the population at risk. These differences, however, can often be mitigated through interrogation of the IPD. Box \ref{box:ipd-events} provides a working definition for initial cure, which is applied during the data harmonisation process.

\begin{mybox}[floatplacement=tb, label=box:ipd-events]{IPD--based working definitions}
    \begin{description}[nosep]
        \item[\textbf{Initial cure}] Where initial cure (or initial treatment failure) is \textit{not} directly recorded in the IPD as an efficacy outcome, or where it is recorded but the study definition considers `slow responders' as initial treatment failures, it can be inferred from (i) improvement of signs and symptoms between baseline and test--of--cure, and (ii) not requiring rescue treatment during initial treatment. Importantly, reflecting both routine clinical practice and a number of study definitions, detection of parasites at test--of--cure should not preclude the subsequent development of relapse, so long as points (i) and (ii) are met.
    \end{description}
    \tcbline
    \begin{description}[nosep]
        \item[\textbf{Relapse}] Where relapse is not directly recorded in the IPD as an efficacy outcome, it can be inferred from (i) absence of rescue treatment within 6 months of test--of--cure assessment, (ii) the presence of a positive tissue aspirate in addition to a recurrence of compatible signs and symptoms.
    \end{description}
\end{mybox}

\subsection{\label{sec:methods-outcome}Outcome}

Relapse itself, where described at the study--level, is also subject to substantial variation with respect to its (i) definition \textemdash\ including the severity of symptoms required to trigger a repeat aspirate and the tissue type chosen for aspirate, and (ii) timing \textemdash\ including whether patients were actively screened at set time points with clinical examination $\pm$ routine aspirates, or whether dependent on patients attended voluntarily based on recurrent symptoms and discharge advice. In line with findings by Dahal et al, a significant proportion of contributing studies do not directly define relapse as a study outcome\cite{dahal2024}. Instead, for most studies, a relapse event can be inferred from patients achieving initial cure who subsequently do not meet the definition of `definite cure', which itself is typically defined as patients requiring rescue treatment.

Similar to the approach described for identifying patients that achieve initial cure, access to IPD allows relapse events to be inferred from other variables, including: definite cure status, tissue aspirates, timing of rescue treatment initiation, and patient signs and symptoms. Box \ref{box:ipd-events} provides an IPD--based working definition of relapse.

Relapse is recorded and modelled as a binary outcome variable (occurred vs. not occurred, or 1/0). Unfortunately, modelling relapse as a time--to--event variable is not feasible, since \textit{timing} information is (i) inconsistently presented across the contributed IPD, and (ii) where presented, is often limited to fixed, predetermined study visits (e.g. 3 months, 6 months).

% Study-specific definitions of initial cure and relapse are presented in \hyperref[sec:add-files]{Additional file 1}.
\section{Model development}

Having created an analysis--ready dataset, model development can now commence. Important steps here include:

\begin{description}[noitemsep]
    \item[Sample size calculations] Section \ref{sec:meth-samp}. To prevent model overfitting, the maximum number of candidate predictors (degrees of freedom) can be calculated.
    \item[Candidate predictors] Section \ref{sec:meth-candidate-pred}. After establishing the degrees of freedom supported by the models, selection and specification of the candidate predictors can be carried out.
    \item[Descriptive analysis] Section \ref{sec:meth-desc}. Description of how the analysis--dataset is presented, informing model specification.
    \item[Missing data] Section \ref{sec:meth-missing}.
    \item[Model specification] Section \ref{sec:meth-spec}.
    \item[Variable selection] Section \ref{sec:meth-vs}.
    \item[Evaluation of model performance] Section \ref{sec:meth-perf}.
\end{description}

\subsection{\label{sec:meth-samp}Sample size}

Sample size methodology developed by Riley et al\cite{riley2019A}, and implemented in the R package \texttt{pmsampsize}\cite{ensor2023}, is used to estimate the maximum number of predictors parameters (degrees of freedom) permitted to prevent overfitting, given the number of IPD and relapse events. To achieve this, Riley et al. propose three criteria: (i) small optimism in predictor effect estimates, defined by a global shrinkage factor of $geq$0.9, (ii) small absolute difference of $\leq$0.05 in the model's apparent and adjusted Nagelkerke's R\textsuperscript{2}, and (iii) precise estimation of the overall risk in the population.

Given the lack of previously published relapse prediction models, we assumed a Nagelkerke R$^2$ of 0.15\cite{riley2019A}.

\subsubsection{ISC model}

With a total of 228 relapses identified among 4,599 participants (5.0\% event rate), the maximum number of predictor parameters satisfying Riley et al.'s three criteria was 25, corresponding to 8.86 events per predictor parameter (EPP). Relaxing the permitted overall shrinkage from 0.90 to 0.85 (modifying criteria (i)) allows for 40 predictor parameters, corresponding to 5.57 EPP.

\subsubsection{East Africa model}

With a total of 99 relapses identified among 2,051 participants (4.8\% event rate), the maximum number of predictor parameters satisfying Riley et al.'s three criteria was 11, corresponding to 8.81 EPP. Relaxing the permitted overall shrinkage from 0.90 to 0.85 (modifying criteria (i)) allows for 18 predictor parameters, corresponding to 5.54 EPP.

\subsection{\label{sec:meth-candidate-pred}Candidate predictors}

Candidate predictors available at the time of starting treatment were selected based on (i) existing evidence and expert opinion regarding their association with relapse\cite{hirve2016, goyal2020, burza2014}, (ii) availability across the contributed datasets; and (iii) feasibility for routine use outside research settings.

For Model~1 (including parasite grade), 16 candidate predictor parameters were included, corresponding to a study-specific random intercept term and 12 participant-level candidate predictors (EPP~=~14.25, with some predictors linked to $>$1 parameter). Candidate predictors consisted of age, sex, treatment regimen, malnutrition, duration of fever before treatment, spleen size, parasite grade from tissue aspirate, severity of anaemia, and a range of laboratory values including white blood cell count (WBC), platelet count, alanine aminotransferase (ALT), and creatinine.

As a marker of malnutrition - and in keeping with previous literature on the association between VL and malnutrition - BMI and BMI-for-age z-scores were used in adults and children/adolescents ($<$18 years) respectively\cite{burza2014,dorlo2017,naylor-leyland2022}. This variable was grouped as three ordered categories: (i) severe malnutrition: BMI $<$16 kg/m$^2$ or BMI-for-age z-score $<$-3; (ii) moderate malnutrition: 16 kg/m$^{2}\leq$ BMI $<$18.5 kg/m$^2$ or -3$\leq$ BMI-for-age z-score $<$-2; and (iii) mild or no malnutrition: BMI $\geq$18.5 kg/m2 or BMI-for-age z-score $\geq$-2. Z-scores were calculated using World Health Organization (WHO) growth standards with R packages \texttt{anthro} and \texttt{anthroplus}\cite{schumacher2023,schumacher2021}.

To account for an anticipated non-linear relationship between age and relapse, age was included as a third-degree polynomial term (linear, squared, and cubic components).

Treatment was categorised into three groups, reflecting current and recent WHO VL treatment guidelines in the Indian subcontinent: (i) 10mg/kg single dose liposomal amphotericin B (SDA), (ii) 28 days of oral miltefosine (standard linear dosing), and (iii) any other medicines or regimens. Further subdivision of the `other' group was not feasible due to the marked heterogeneity of treatment regimens across the contributing studies.
Anaemia was grouped into two categories: severe and non-severe, using haemoglobin cut-offs stratified by age and sex thresholds, as per 2024 WHO guidance\cite{who_haem2024}. Additional subdivision of the non-severe anaemia group was limited by the small number of participants in the mild and normal categories.

Baseline parasite grade, when available, was assessed from splenic or bone marrow aspirates (with Nepalese studies preferentially using the latter). When reported, the logarithmic counting method of Chulay and Bryceson (1983) was either described or directly cited {Additional file 1}\cite{chulay1983}.

Continuous predictors - including fever duration, spleen length, and all blood tests except haemoglobin - were log-transformed to reduce skewness and better approximate normality. For spleen size, a value of 1 was added prior to transformation to accommodate zero values and avoid undefined logarithmic results. For parasite count, a value of 1 was subtracted to better approximate a Poisson distribution in the imputation model.

\subsection{\label{sec:meth-desc}Descriptive analysis}

\subsection{\label{sec:meth-missing}}

Missing data were common and resulted from (i) planned non-capture at the study-level (ii) unplanned incomplete capture of the predictor at the study-level, or (iii) incomplete IPD in the contributed dataset. Outcome data were complete.

We used multiple imputation with chained equations (MICE) to handle missing data and assumed missingness at random (MAR) \cite{white2011,van_buuren2021}. All ungrouped candidate predictors, as well as weight, height and the outcome (relapse) were included in the imputation model. Derived predictors, including BMI, BMI-for-age z-score, and higher order age polynomial terms, were passively imputed from age, weight and height. Grouping of haemoglobin, BMI and BMI-for-age z-score occurred after imputation. We used the R package \texttt{mice}, with addon packages \texttt{countimp} for non-hierarchical count data (modelling parasite grade) and \texttt{micemd} for two-level continuous data (modelling the remaining variables, accounting for study-level heterogeneity and systematically missing data)\cite{van-buuren2011,kleinke2024,audigier2023,audigier2018}.

For each model development, 20 imputations were performed with 20 iterations per imputation. Convergence of the imputation models was inspected visually with trace plots and by comparing distributions of imputed data with the complete data.

The same imputation model was used for the development of both Model~1 and Model~2. The MAR assumption and convergence of the imputation model were assessed visually with diagnostic plots. These included trace plots and plots comparing the original and imputed data (including density plots and scatter plots for age, height, and weight). Full specification of the imputation model methods, predictor matrix, passive imputation specifications, and post imputation calculations are provided in ...

\subsection{\label{sec:meth-spec}Model specification}
\subsection{\label{sec:meth-vs}Variable selection}

Six-month relapse was modelled as a binary outcome in a multivariable generalised linear mixed-effects model (GLMM) with a logit link function. Predictors were transformed as previously described. Anticipated between-study heterogeneity was accounted for by including study as a random intercept term\cite{bouwmeester2013A}. Whilst introducing methodological complexity, there are a number of benefits gained by accounting for between-study heterogeneity\cite{debray2023}:

\begin{itemize}
    \item Ignoring clustering can result in relapse probability estimates that are biased towards the overall study population estimate\cite{wynants2018}.
    \item Variation in model performance measures can be compared and contrasted across the included studies, allowing insights into sources of heterogeneity\cite{steyerberg2019}.
    \item Allows for improved generalisability of the model to new settings and populations\cite{debray2023,steyerberg2019}.
\end{itemize}

Model parameters were estimated using the \texttt{glmer} function from the \texttt{lme4} package in R with the BOBYQA algorithm\cite{bates2015,powell2009}.

The final predictor set was determined using backwards variable selection with cutoff p $<$0.10. Rubin's rules were used to combine predictor estimates and test predictor significance at each selection stage across the 20 imputed datasets\cite{austin2019,rubin1987}. For categorical predictors with over two groups (malnutrition, treatment), predictor significance was assessed with the D1 multivariate Wald test as implemented in the \texttt{mice} R package\cite{van-buuren2011,li1991}. For age, lower-order polynomial terms were retained in the model whilst higher-order terms remained.

\subsection{\label{sec:meth-perf}Model performance}

Model discrimination was assessed using the c-statistic, and calibration using calibration slope, and calibration intercept and calibration plots. Within-study (conditional) performance measures are presented, reflecting model performance when evaluated at the study level\cite{wynants2018,van-klaveren2014}.

C-statistics with 95\% confidence intervals were calculated with bootstrapping (n~=~500). Bootstrap samples were then pooled across multiple imputations using the `MI Boot (PS)' method described by Schomaker et al\cite{schomaker2018}. Calibration slope and intercept were pooled across imputed datasets using Rubin's rules.

For constructing calibration plots, the mean predicted and observed relapse probabilities were calculated across selected subgroups in the combined imputed datasets. Predicted probabilities were calibrated at the study level with logistic recalibration. Study-specific calibrated probabilities were estimated with best linear unbiased predictors. Binomial confidence intervals for the mean observed probabilities were estimated using Wilson's method. To account for multiple imputation, the number of relapses and corresponding denominators were averaged across imputations (i.e. divided by 20) prior to interval calculation. The continuous relationship between observed relapse probability and predicted probabilities was modelled using a generalised additive model with standard errors inflated by $\sqrt{20}$ to adjust for the inflated sample size from multiple imputations.

Performance heterogeneity across the contributing studies was assessed with aggregate random-effects meta-analyses using the R package \texttt{metafor}\cite{viechtbauer2010}. Between-study variance was estimated with restricted maximum likelihood and 95\% confidence and prediction intervals were estimated with the Hartung-Knapp-Sidik-Jonkman method. C-statistics were pooled on the logit scale, and calibration slope and interval were pooled on their original scale\cite{snell2018}.

\section{Internal validation}

Internal validation was performed using bootstrapping at the participant level to (i) adjust performance measures and parameter estimates for model overfitting (optimism and uniform shrinkage), and (ii) evaluate model stability by reviewing the variation in model selection across different bootstrap samples\cite{collins2024B, bouwmeester2013B}. For each of the 500 bootstrap samples of the original dataset, full model development was performed including multiple imputation. Performance measures were evaluated for each bootstrap model in (i) the imputed bootstrap datasets used to derive the bootstrap model and (ii) the imputed original datasets used to derive the original model. The performance (optimism) difference between (i) and (ii) was calculated. The average (mean) optimism across the 500 bootstrap models was then subtracted from the original model apparent performance measures to obtain the optimism adjusted performance measures. Uniform shrinkage of the parameter estimates was performed. The University of Oxford Biomedical Research Computing cluster was used due to the high computational demand of performing bootstrapping with both multiple imputation with GLMM fitting.


\section{Conclusion}
